{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a1a25a",
   "metadata": {},
   "source": [
    "# 타이타닉 생존자 예측 (v1)\n",
    "- 입력: 데이터의 독립변인 전부 (적은 게 좋음)\n",
    "- 결과: 생존자를 예측(0/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408f9b21",
   "metadata": {},
   "source": [
    "## 과정\n",
    "1. 데이터 불러오기\n",
    "2. 데이터 전처리\n",
    "3. 데이터 분할\n",
    "4. 데이터 정규화\n",
    "------\n",
    "5. 학습/검증/테스트 데이터 (텐서로 변경해야 함)\n",
    "6. 모델 생성 (a. 베이스 라인, b. 개선)\n",
    "7. 학습\n",
    "8. 예측\n",
    "9. 평가\n",
    "* (5번부터 PyTorch 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ebbd602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "171e1f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 불러오기\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # [확인해야 할 것]\n",
    "    # 1. 형태(행, 열 크기)\n",
    "    # - 열(독립변인, 측정값)\n",
    "    # - 행(종속변인, 관측값)\n",
    "    # 2. 자료형(info)\n",
    "    # 3. 컬럼 이름\n",
    "    print(f'\\n결측치 : {df.isnull().sum()}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5b5cb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결측치 : PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = load_data('data/titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41d71137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce7e3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 전처리\n",
    "def preporcess_data(df):\n",
    "    df = df.copy()\n",
    "    target_col = 'Survived'\n",
    "    \n",
    "    # 타깃 변수가 결측인 행 제거\n",
    "    df = df.dropna(subset=[target_col])      \n",
    "    columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # 데이터 값 숫자로 바꾸기\n",
    "    if 'Sex' in df.columns:\n",
    "        df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    if 'Embarked' in df.columns:\n",
    "        df = pd.get_dummies(df, columns=['Embarked'], prefix='Embarked')\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.to_list()\n",
    "    feature_cols = [col for col in numeric_cols if col != target_col]\n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[target_col].copy()\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    return X.values, y.values, feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb2ec0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터 분할\n",
    "def split_data(X, y, train_ratio=0.8):\n",
    "    n_samples = len(X)\n",
    "    n_train = int(n_samples * train_ratio)\n",
    "\n",
    "    indices = np.random.permutation(n_samples)  # 셔플 필수\n",
    "    train_indices = indices[:n_train]\n",
    "    test_indices = indices[n_train:]\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    X_test = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eab82ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 데이터 정규화\n",
    "# (평균 = 0, 표준편차 = 1)\n",
    "\n",
    "def normalize_features(X_train, X_test):\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0) + 1e-8\n",
    "\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_test_norm = (X_test - mean) / std\n",
    "\n",
    "    return X_train_norm, X_test_norm, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22eae421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 학습/검증/테스트 데이터\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y)    # 분류 문제라서 LongTensor 사용\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "864cc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 모델 생성\n",
    "class LinearClassficationModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LinearClassficationModel, self).__init__()\n",
    "        # self.linear = nn.Linear(input_dim, num_classes)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ffe84ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 학습\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=100):\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    acc_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()   # 기울기 0으로 고정\n",
    "            predictions = model(batch_X)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 측정\n",
    "            epoch_loss += loss.item()\n",
    "            _, predicted = torch.max(predictions.data, 1)   # 열을 없애고 → 행마다 결과 1개\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        acc = 100 * correct / total\n",
    "        loss_history.append(avg_loss)\n",
    "        acc_history.append(acc)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'{epoch + 1} : {avg_loss}, {acc}')\n",
    "            \n",
    "    return loss_history, acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 평가\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            pred = model(batch_X)\n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            predictions.extend(predicted.numpy())\n",
    "            actuals.extend(batch_y.numpy())\n",
    "\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "\n",
    "    print(f'\\n=== 테스트 세트 평가 ===')\n",
    "    print(f'Accuarcy: {accuracy}')\n",
    "    print(f'Correct: {correct}/{total}')\n",
    "\n",
    "    return predictions, actuals, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b982dd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "결측치 : PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "10 : 0.7136646146359651, 46.91011235955056\n",
      "20 : 0.5499602698761484, 78.51123595505618\n",
      "30 : 0.4976226842921713, 78.08988764044943\n",
      "40 : 0.4748382412868997, 79.49438202247191\n",
      "50 : 0.45735851707665814, 79.21348314606742\n",
      "60 : 0.43828727499298425, 79.49438202247191\n",
      "70 : 0.44423243144284125, 79.21348314606742\n",
      "80 : 0.4351071229447489, 79.35393258426966\n",
      "90 : 0.44191490696824115, 79.21348314606742\n",
      "100 : 0.4483886970126111, 79.21348314606742\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 179 is out of bounds for dimension 0 with size 179",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m train_model(model, train_loader, criterion, optimizer)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 9. 평가\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m predictions, actuals, accuracy = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, test_loader)\u001b[39m\n\u001b[32m      7\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\venvs\\DS_Coding\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\venvs\\DS_Coding\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\venvs\\DS_Coding\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mTitanicDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.X[index], \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: index 179 is out of bounds for dimension 0 with size 179"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 불러오기\n",
    "df = load_data('data/titanic/train.csv')\n",
    "# 2. 데이터 전처리\n",
    "X, y, feature_cols = preporcess_data(df)\n",
    "# 3. 데이터 분할\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "# 4. 데이터 정규화\n",
    "X_train_norm, X_test_norm, mean, std = normalize_features(X_train, X_test)\n",
    "# 5. 학습/검증/테스트 데이터\n",
    "train_dataset = TitanicDataset(X_train_norm, y_train)\n",
    "test_dataset = TitanicDataset(X_test_norm, y_test)\n",
    "\n",
    "batch_size = 32     # 하이퍼 파라미터\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# 6. 모델 생성\n",
    "# 초기 데이터의 크기와 결과에 대해 미리 알고 있어야 함\n",
    "input_dim = X_train_norm.shape[1]\n",
    "num_classes = 2\n",
    "model = LinearClassficationModel(input_dim, num_classes)\n",
    "# 7. 학습\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "# 9. 평가\n",
    "predictions, actuals, accuracy = evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b2a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb2a8e",
   "metadata": {},
   "source": [
    "# 연습 1. 배치사이즈 4(데이터의 개수), (강아지, 고양이, 코끼리)를 분류하는 모델로 가정\n",
    "\n",
    "(1) 모델의 예측과 오차(predictions)\n",
    "데이터1: [0.1, 0.8, 0.1]    -> 고양이 1\n",
    "데이터2: [0.2, 0.2, 0.6]    -> 코끼리 2\n",
    "데이터3: [0.7, 0.2, 0.1]    -> 강아지 0\n",
    "데이터4: [0.3, 0.4, 0.3]    -> 고양이 1\n",
    "\n",
    "(2) 실제정답: [1, 2, 1, 1]\n",
    "\n",
    "(3) 학습평가(predicted) [1, 2, 0, 1] => [1, 1, 0, 1]\n",
    "\n",
    "(4) 평가(correct)\n",
    "\n",
    "(5) 오차누적(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_Coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
