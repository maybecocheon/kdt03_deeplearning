# 파이토치 2.9
## 활성화 함수: 신경망, 뉴런, "비선형성"을 부여, 복잡한 패턴을 학습하는 데 도움
- 1세대(고전): sigmoid, tanh => 속도 좀 느림, 기울기 소실
- 2세대(ReLU): ReLU => 기울기 소실 문제를 해결
- 3세대(확률): GELU(트랜스포머) => 언어 모델에서 표준, 입력에 따른 가중치 부여
- 4세대(진화): Mish(Swish)
-----
> 은닉층
- Tanh: RNN/LSTM에 주로 사용
- ReLU: CNN에 주로 사용
- GELU: 트랜스포머에 주로 사용
-----
> 출력층
- 이진 분류의 출력층: sigmoid
- 다중 분류의 출력층: softmax
-----
> 손실함수: 예측값(y_hat)과 실제값(label) 간의 차이를 측정
- 1세대: 고전 -> MSE
- 2세대: 기계 -> Cross Entropy
- 3세대: 딥러닝 -> Focal, Label Smoothing, Triplet Loss
-----
- 다중 클래스: Cross Entropy
- 이진 분류: BCEwithLogitsLoss(멀티 라벨 분류)
- 회귀: MSELoss
-----
## 최적화 함수: 손실 함수의 기울기를 이용해서 모델의 가중치를 업데이트하는 것
- 1세대: 고전 => SGD(1951)
- 2세대: (파라미터별) 적응 => RMSprop: 학습률 감소 문제를 완만
- 3세대: (현대) 적응 => Adam
- 4세대: (대규모) 적응 => LAMB
-----
- SGD: 모든 작업에 다 어울림 단, 튜닝이 너무 힘듦
- RMSProp: RNN(구형), 튜닝 애매
- AdamW: 모든 작업에 다 어울림 그리고 튜닝 할 만함
